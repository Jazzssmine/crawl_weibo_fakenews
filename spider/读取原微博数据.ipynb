{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**原微博**\n",
    "* 内容--done\n",
    "* 发布时间--done\n",
    "* 点赞/转发数--done\n",
    "* 评论数/评论内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "import urllib\n",
    "import re\n",
    "import unidecode\n",
    "import time\n",
    "import requests\n",
    "from requests import Request, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari / 537.36'\n",
    "}\n",
    "cookie = {\n",
    "    'ALF': '1569558716', \n",
    "    'SCF': 'Am7Jt7ySAY5qGVf-9s3G4Of_Q9InAuL_1ZZY7JWBEh1EiWnBRLXtcSh1nR4wbrIyDDff11BLAnQju0tu2lJWWvw.',\n",
    "    'SUBP': '0033WrSXqPxfM725Ws9jqgMF55529P9D9WWJcHiLLQYmQJX._sM6GNLg5JpX5KzhUgL.FoeX1h-7ehMcehM2dJLoIN-LxKMLB.zL1hnLxKBLB.2L12-LxK-L12qLB-qLxKBLB.zLBK-LxKqL1KBLBo.LxK-L1K5L12BLxKBLB.2L1hqLxK-L12qL1hnLxKnLBKqL1h2LxK-L1K5L12-LxKqL1hzL1KBLxKBLBonL1h5LxK-LBo.LBoBt', \n",
    "    '_T_WM': '61257250789',\n",
    "    'SUB': '_2A25wYnR2DeRhGeVK41cR8CnKyzuIHXVTrRw-rDV6PUJbkdBeLVeskW1NTCdnposyBx280rTF2p9x6qqSkZWoX8eQ', \n",
    "    'SUHB': '0YhRmMMZUqsJLt' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_path = []\n",
    "for i in range(0, 50):\n",
    "    crawl_path.append('crawl_data/text_data' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for j in range(0, 5):\\n    crawl_data = pd.read_csv(crawl_path[j])\\n    weibo_content = []\\n    repost_num = []\\n    thumbs_num = []\\n    comment_num = []\\n    comments_all = []\\n    for i in range(0, 20):\\n        print(i)\\n        url = crawl_data[\\'link_to_post\\'][i]\\n        if url != \\'nn\\':\\n            r = requests.get(url, cookies=cookie)\\n            content = r.text\\n            soup = BeautifulSoup(content, \\'lxml\\')\\n        \\n            ##微博内容\\n            for item in soup.select(\\'div[class=\"c\"] div span[class=\"ctt\"]\\' ):\\n                weibo_content.append(item.get_text())\\n                #print(weibo_content)\\n            \\n            ##转发\\n            for item in soup.findAll(\"a\",{\"href\":re.compile(\"\\\\/repost\\\\/(.+)\")}):\\n                repost = re.findall(r\\'[0-9]+\\', str(item.get_text()))\\n                if len(repost) == 0:\\n                    repost_num.append(\\'0\\')\\n                else:\\n                    repost_num.append(repost[0])\\n                #print(repost_num)\\n                \\n            ##赞\\n            for item in soup.findAll(\"a\",{\"href\":re.compile(\"\\\\/attitude\\\\/(.+)\\\\?\\\\#\")}):\\n                thumbs = re.findall(r\\'[0-9]+\\', str(item.get_text()))\\n                thumbs_num.append(thumbs[0])\\n            \\n            ##评论数\\n            for item in soup.findAll(\\'span\\', {\\'class\\': \\'pms\\'}):\\n                comment = re.findall(r\\'[0-9]+\\', str(item.get_text()))\\n                if len(comment) == 0:\\n                    comment_num.append(\\'0\\')\\n                else:\\n                    comment_num.append(comment[0])\\n        \\n            if len(soup.select(\\'div[class=\"c\"] div span[class=\"ctt\"]\\' )) == 0:\\n                weibo_content.append(\\'no access\\')\\n                repost_num.append(\\'no access\\')\\n                thumbs_num.append(\\'no access\\')\\n                comment_num.append(\\'no access\\')\\n                \\n        else:\\n            print(\\'deleted\\')\\n            weibo_content.append(\\'deleted\\')\\n            repost_num.append(\\'deleted\\')\\n            thumbs_num.append(\\'deleted\\')\\n            comment_num.append(\\'deleted\\')\\n    \\n    ##评论\\n    for i in range(0, 20):\\n        url = crawl_data[\\'link_to_post\\'][i]\\n        comments = []\\n        if url != \\'nn\\':\\n            r = requests.get(url, cookies=cookie)\\n            content = r.text\\n            soup = BeautifulSoup(content, \\'lxml\\')\\n            #print(url)        \\n            ## 页数\\n            if len(soup.select(\\'div[class=\"pa\"] form div input\\')) == 0:\\n                comments.append(\\'no comment accessible\\')\\n            else:\\n                page_une = soup.select(\\'div[class=\"pa\"] form div input\\')[0]\\n                page_num = re.findall(r\"\\\\d+\",str(page_une))\\n        \\n                for p in range(1, min(4, int(page_num[0]) + 1)):\\n                    comment_web = url + \\'?page=\\' + str(p)\\n                    comment_r = requests.get(comment_web, cookies=cookie)\\n                    comment = comment_r.text\\n                    comment_soup = BeautifulSoup(comment, \\'lxml\\')\\n                    for item in comment_soup.select(\\'div[class=\"c\"] span[class=\"ctt\"]\\'):\\n                        cc = item.get_text()\\n                        comments.append(cc)\\n\\n        else:\\n            print(\"deleted\")\\n            comments.append(\\'deleted\\')\\n    \\n        comments_all.append(comments)\\n    \\n    \\n    \\n    crawl_data[\\'comments\\'] = comments_all\\n    crawl_data[\\'weibo_content\\'] = weibo_content\\n    crawl_data[\\'repost_num\\'] = repost_num\\n    crawl_data[\\'thumbs_up\\'] = thumbs_num\\n    crawl_data[\\'comment_num\\'] = comment_num\\n    crawl_data.to_csv(\\'crawl_data/crawl_\\' + str(j) + \\'.csv\\')'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for j in range(0, 5):\n",
    "    crawl_data = pd.read_csv(crawl_path[j])\n",
    "    weibo_content = []\n",
    "    repost_num = []\n",
    "    thumbs_num = []\n",
    "    comment_num = []\n",
    "    comments_all = []\n",
    "    for i in range(0, 20):\n",
    "        print(i)\n",
    "        url = crawl_data['link_to_post'][i]\n",
    "        if url != 'nn':\n",
    "            r = requests.get(url, cookies=cookie)\n",
    "            content = r.text\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "        \n",
    "            ##微博内容\n",
    "            for item in soup.select('div[class=\"c\"] div span[class=\"ctt\"]' ):\n",
    "                weibo_content.append(item.get_text())\n",
    "                #print(weibo_content)\n",
    "            \n",
    "            ##转发\n",
    "            for item in soup.findAll(\"a\",{\"href\":re.compile(\"\\/repost\\/(.+)\")}):\n",
    "                repost = re.findall(r'[0-9]+', str(item.get_text()))\n",
    "                if len(repost) == 0:\n",
    "                    repost_num.append('0')\n",
    "                else:\n",
    "                    repost_num.append(repost[0])\n",
    "                #print(repost_num)\n",
    "                \n",
    "            ##赞\n",
    "            for item in soup.findAll(\"a\",{\"href\":re.compile(\"\\/attitude\\/(.+)\\?\\#\")}):\n",
    "                thumbs = re.findall(r'[0-9]+', str(item.get_text()))\n",
    "                thumbs_num.append(thumbs[0])\n",
    "            \n",
    "            ##评论数\n",
    "            for item in soup.findAll('span', {'class': 'pms'}):\n",
    "                comment = re.findall(r'[0-9]+', str(item.get_text()))\n",
    "                if len(comment) == 0:\n",
    "                    comment_num.append('0')\n",
    "                else:\n",
    "                    comment_num.append(comment[0])\n",
    "        \n",
    "            if len(soup.select('div[class=\"c\"] div span[class=\"ctt\"]' )) == 0:\n",
    "                weibo_content.append('no access')\n",
    "                repost_num.append('no access')\n",
    "                thumbs_num.append('no access')\n",
    "                comment_num.append('no access')\n",
    "                \n",
    "        else:\n",
    "            print('deleted')\n",
    "            weibo_content.append('deleted')\n",
    "            repost_num.append('deleted')\n",
    "            thumbs_num.append('deleted')\n",
    "            comment_num.append('deleted')\n",
    "    \n",
    "    ##评论\n",
    "    for i in range(0, 20):\n",
    "        url = crawl_data['link_to_post'][i]\n",
    "        comments = []\n",
    "        if url != 'nn':\n",
    "            r = requests.get(url, cookies=cookie)\n",
    "            content = r.text\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "            #print(url)        \n",
    "            ## 页数\n",
    "            if len(soup.select('div[class=\"pa\"] form div input')) == 0:\n",
    "                comments.append('no comment accessible')\n",
    "            else:\n",
    "                page_une = soup.select('div[class=\"pa\"] form div input')[0]\n",
    "                page_num = re.findall(r\"\\d+\",str(page_une))\n",
    "        \n",
    "                for p in range(1, min(4, int(page_num[0]) + 1)):\n",
    "                    comment_web = url + '?page=' + str(p)\n",
    "                    comment_r = requests.get(comment_web, cookies=cookie)\n",
    "                    comment = comment_r.text\n",
    "                    comment_soup = BeautifulSoup(comment, 'lxml')\n",
    "                    for item in comment_soup.select('div[class=\"c\"] span[class=\"ctt\"]'):\n",
    "                        cc = item.get_text()\n",
    "                        comments.append(cc)\n",
    "\n",
    "        else:\n",
    "            print(\"deleted\")\n",
    "            comments.append('deleted')\n",
    "    \n",
    "        comments_all.append(comments)\n",
    "    \n",
    "    \n",
    "    \n",
    "    crawl_data['comments'] = comments_all\n",
    "    crawl_data['weibo_content'] = weibo_content\n",
    "    crawl_data['repost_num'] = repost_num\n",
    "    crawl_data['thumbs_up'] = thumbs_num\n",
    "    crawl_data['comment_num'] = comment_num\n",
    "    crawl_data.to_csv('crawl_data/crawl_' + str(j) + '.csv')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "deleted\n",
      "17\n",
      "deleted\n",
      "18\n",
      "19\n",
      "deleted\n",
      "deleted\n"
     ]
    }
   ],
   "source": [
    "crawl_data = pd.read_csv(crawl_path[2])\n",
    "weibo_content = []\n",
    "repost_num = []\n",
    "thumbs_num = []\n",
    "comment_num = []\n",
    "comments_all = []\n",
    "for i in range(0, 20):\n",
    "    print(i)\n",
    "    url = crawl_data['link_to_post'][i]\n",
    "    if url != 'nn':\n",
    "        r = requests.get(url, cookies=cookie)\n",
    "        content = r.text\n",
    "        soup = BeautifulSoup(content, 'lxml')\n",
    "        \n",
    "        ##微博内容\n",
    "        for item in soup.select('div[class=\"c\"] div span[class=\"ctt\"]' ):\n",
    "            weibo_content.append(item.get_text())\n",
    "            \n",
    "        ##转发\n",
    "        for item in soup.findAll(\"a\",{\"href\":re.compile(\"\\/repost\\/(.+)\")}):\n",
    "            repost = re.findall(r'[0-9]+', str(item.get_text()))\n",
    "            if len(repost) == 0:\n",
    "                repost_num.append('0')\n",
    "            else:\n",
    "                repost_num.append(repost[0])\n",
    "                \n",
    "        ##赞\n",
    "        for item in soup.findAll(\"a\",{\"href\":re.compile(\"\\/attitude\\/(.+)\\?\\#\")}):\n",
    "            thumbs = re.findall(r'[0-9]+', str(item.get_text()))\n",
    "            thumbs_num.append(thumbs[0])\n",
    "            \n",
    "        ##评论数\n",
    "        for item in soup.findAll('span', {'class': 'pms'}):\n",
    "            comment = re.findall(r'[0-9]+', str(item.get_text()))\n",
    "            if len(comment) == 0:\n",
    "                comment_num.append('0')\n",
    "            else:\n",
    "                comment_num.append(comment[0])\n",
    "        \n",
    "        if len(soup.select('div[class=\"c\"] div span[class=\"ctt\"]' )) == 0:\n",
    "            weibo_content.append('no access')\n",
    "            repost_num.append('no access')\n",
    "            thumbs_num.append('no access')\n",
    "            comment_num.append('no access')\n",
    "                \n",
    "    else:\n",
    "        print('deleted')\n",
    "        weibo_content.append('deleted')\n",
    "        repost_num.append('deleted')\n",
    "        thumbs_num.append('deleted')\n",
    "        comment_num.append('deleted')\n",
    "    \n",
    "##评论\n",
    "for i in range(0, 20):\n",
    "    url = crawl_data['link_to_post'][i]\n",
    "    comments = []\n",
    "    if url != 'nn':\n",
    "        r = requests.get(url, cookies=cookie)\n",
    "        content = r.text\n",
    "        soup = BeautifulSoup(content, 'lxml')       \n",
    "        ## 页数\n",
    "        if len(soup.select('div[class=\"pa\"] form div input')) == 0:\n",
    "            comments.append('no comment accessible')\n",
    "        else:\n",
    "            page_une = soup.select('div[class=\"pa\"] form div input')[0]\n",
    "            page_num = re.findall(r\"\\d+\",str(page_une))\n",
    "        \n",
    "            for p in range(1, min(4, int(page_num[0]) + 1)):\n",
    "                comment_web = url + '?page=' + str(p)\n",
    "                comment_r = requests.get(comment_web, cookies=cookie)\n",
    "                comment = comment_r.text\n",
    "                comment_soup = BeautifulSoup(comment, 'lxml')\n",
    "                for item in comment_soup.select('div[class=\"c\"] span[class=\"ctt\"]'):\n",
    "                    cc = item.get_text()\n",
    "                    comments.append(cc)\n",
    "\n",
    "    else:\n",
    "        print(\"deleted\")\n",
    "        comments.append('deleted')\n",
    "    \n",
    "    comments_all.append(comments)\n",
    "    \n",
    "    \n",
    "    \n",
    "crawl_data['comments'] = comments_all\n",
    "crawl_data['weibo_content'] = weibo_content\n",
    "crawl_data['repost_num'] = repost_num\n",
    "crawl_data['thumbs_up'] = thumbs_num\n",
    "crawl_data['comment_num'] = comment_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://weibo.cn/comment/I1tm7zm98\n",
      "https://weibo.cn/comment/I1yLyzrSI\n",
      "https://weibo.cn/comment/I1rg3Acxm\n",
      "https://weibo.cn/comment/I1rjuCZCd\n",
      "https://weibo.cn/comment/I1sxOmaRI\n",
      "https://weibo.cn/comment/I1yiyf91T\n",
      "https://weibo.cn/comment/I1rEz341I\n",
      "https://weibo.cn/comment/I1r4LAqjo\n",
      "https://weibo.cn/comment/I1sKW9ult\n",
      "https://weibo.cn/comment/I1pJLzBkT\n",
      "https://weibo.cn/comment/I1yTU02qd\n",
      "https://weibo.cn/comment/I1xzHCAI0\n",
      "https://weibo.cn/comment/I1przmR59\n",
      "https://weibo.cn/comment/I1qU4ur1S\n",
      "https://weibo.cn/comment/I1sV3rl76\n",
      "https://weibo.cn/comment/I1Crq76cs\n",
      "deleted\n",
      "deleted\n",
      "https://weibo.cn/comment/I1BeShFSq\n",
      "https://weibo.cn/comment/I1revf6wd\n"
     ]
    }
   ],
   "source": [
    "comments_all = []\n",
    "for i in range(0, 20):\n",
    "    url = crawl_data['link_to_post'][i]\n",
    "    comments = []\n",
    "    if url != 'nn':\n",
    "        r = requests.get(url, cookies=cookie)\n",
    "        content = r.text\n",
    "        soup = BeautifulSoup(content, 'lxml')\n",
    "        print(url)        \n",
    "        ## 页数\n",
    "        if len(soup.select('div[class=\"pa\"] form div input')) == 0:\n",
    "            comments.append('no comment accessible')\n",
    "        else:\n",
    "            page_une = soup.select('div[class=\"pa\"] form div input')[0]\n",
    "            page_num = re.findall(r\"\\d+\",str(page_une))\n",
    "        \n",
    "            for p in range(1, min(4, int(page_num[0]) + 1)):\n",
    "                comment_web = url + '?page=' + str(p)\n",
    "                comment_r = requests.get(comment_web, cookies=cookie)\n",
    "                comment = comment_r.text\n",
    "                comment_soup = BeautifulSoup(comment, 'lxml')\n",
    "                for item in comment_soup.select('div[class=\"c\"] span[class=\"ctt\"]'):\n",
    "                    cc = item.get_text()\n",
    "                    comments.append(cc)\n",
    "\n",
    "    else:\n",
    "        print(\"deleted\")\n",
    "        comments.append('deleted')\n",
    "    \n",
    "    comments_all.append(comments)\n",
    "\n",
    "crawl_data['comments'] = comments_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_data.to_csv('crawl_data/crawl_' + str(2) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view_num</th>\n",
       "      <th>inform_num</th>\n",
       "      <th>reported_id</th>\n",
       "      <th>reported_address</th>\n",
       "      <th>post_time</th>\n",
       "      <th>link_to_post</th>\n",
       "      <th>reported_credit</th>\n",
       "      <th>comments</th>\n",
       "      <th>weibo_content</th>\n",
       "      <th>repost_num</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>comment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>5144465848</td>\n",
       "      <td>北京</td>\n",
       "      <td>2019-08-09 22:54:39</td>\n",
       "      <td>https://weibo.cn/comment/I1tm7zm98</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:【8岁女孩因无钱治病, 向父母连说三声“谢谢”, 自拔氧气管离世</td>\n",
       "      <td>42</td>\n",
       "      <td>508</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>6557230118</td>\n",
       "      <td>其他</td>\n",
       "      <td>2019-08-10 12:41:03</td>\n",
       "      <td>https://weibo.cn/comment/I1yLyzrSI</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:【8岁女孩因无钱治病, 向父母连说三声“谢谢”, 自拔氧气管离世</td>\n",
       "      <td>12</td>\n",
       "      <td>156</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2704669457</td>\n",
       "      <td>山东</td>\n",
       "      <td>2019-08-09 17:34:13</td>\n",
       "      <td>https://weibo.cn/comment/I1rg3Acxm</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:中国天气网讯 中央气象台8月9日6时发布台风🌀红色预警。预计，“利奇马”将以每小时20公里...</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5679726425</td>\n",
       "      <td>其他</td>\n",
       "      <td>2019-08-09 17:42:41</td>\n",
       "      <td>https://weibo.cn/comment/I1rjuCZCd</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:这次台风🌀（利奇马）登陆乐清湾 http://t.cn/AiTCHF22</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7267952918</td>\n",
       "      <td>北京</td>\n",
       "      <td>2019-08-09 20:50:41</td>\n",
       "      <td>https://weibo.cn/comment/I1sxOmaRI</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:分享视频 台州 http://t.cn/AiTpSJSD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1885799302</td>\n",
       "      <td>浙江</td>\n",
       "      <td>2019-08-10 11:29:35</td>\n",
       "      <td>https://weibo.cn/comment/I1yiyf91T</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#风王利奇马登陆浙江温岭#  台风登陆现场：所经之处四处“飞沙走石”，连汽车也站不稳啊！ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6321164854</td>\n",
       "      <td>其他</td>\n",
       "      <td>2019-08-09 18:34:35</td>\n",
       "      <td>https://weibo.cn/comment/I1rEz341I</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:台风天 台州·金都花园 http://t.cn/AiTNGcT3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>5974658278</td>\n",
       "      <td>浙江</td>\n",
       "      <td>2019-08-09 17:06:24</td>\n",
       "      <td>https://weibo.cn/comment/I1r4LAqjo</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:台州最新资讯真的要哈厮人啊#台风##台州# 临沂 http://t.cn/AiTCfXZW</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1915596045</td>\n",
       "      <td>上海</td>\n",
       "      <td>2019-08-09 21:23:02</td>\n",
       "      <td>https://weibo.cn/comment/I1sKW9ult</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#超强台风利奇马来了# 没事别出门，出门注意安全！ http://t.cn/AiTpTnH2</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1799653220</td>\n",
       "      <td>山东</td>\n",
       "      <td>2019-08-09 13:41:55</td>\n",
       "      <td>https://weibo.cn/comment/I1pJLzBkT</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#浙江台风# 台州 http://t.cn/AiTKfZXm</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>2966521665</td>\n",
       "      <td>广东</td>\n",
       "      <td>2019-08-10 13:01:35</td>\n",
       "      <td>https://weibo.cn/comment/I1yTU02qd</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#宁波一村庄爆发山洪#看看椒江一桥二桥多严重，在浙江的朋友们小心#台风利奇马# http:...</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5040718691</td>\n",
       "      <td>广东</td>\n",
       "      <td>2019-08-10 09:39:05</td>\n",
       "      <td>https://weibo.cn/comment/I1xzHCAI0</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#浙江台风##台风利奇马#继续跟进报道，工地吊机吹倒砸向附近居民楼，胆小者勿入，以免引起极...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3676552201</td>\n",
       "      <td>其他</td>\n",
       "      <td>2019-08-09 12:57:04</td>\n",
       "      <td>https://weibo.cn/comment/I1przmR59</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:特大台风席卷台州 台州 狂歌走天涯331004的微博视频</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2614436545</td>\n",
       "      <td>浙江</td>\n",
       "      <td>2019-08-09 16:40:03</td>\n",
       "      <td>https://weibo.cn/comment/I1qU4ur1S</td>\n",
       "      <td>['正常']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:台风你真的很可怕</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>3807973089</td>\n",
       "      <td>广西</td>\n",
       "      <td>2019-08-09 21:47:58</td>\n",
       "      <td>https://weibo.cn/comment/I1sV3rl76</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#台风天骑手停送外卖##台风# 请给暴风雨中的这个外卖小哥点赞</td>\n",
       "      <td>117</td>\n",
       "      <td>4561</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2866073222</td>\n",
       "      <td>江苏</td>\n",
       "      <td>2019-08-10 22:02:25</td>\n",
       "      <td>https://weibo.cn/comment/I1Crq76cs</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#台风利奇马已致417万人受灾#鸟瞰台风“利奇马”，横扫人类，如世界末日席卷而来。太恐怖！...</td>\n",
       "      <td>23</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2924424367</td>\n",
       "      <td>上海</td>\n",
       "      <td>None</td>\n",
       "      <td>nn</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>deleted</td>\n",
       "      <td>deleted</td>\n",
       "      <td>deleted</td>\n",
       "      <td>deleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3347738904</td>\n",
       "      <td>山东</td>\n",
       "      <td>None</td>\n",
       "      <td>nn</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>deleted</td>\n",
       "      <td>deleted</td>\n",
       "      <td>deleted</td>\n",
       "      <td>deleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>5311097831</td>\n",
       "      <td>河北</td>\n",
       "      <td>2019-08-10 18:58:46</td>\n",
       "      <td>https://weibo.cn/comment/I1BeShFSq</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:#台风眼##临海全市被淹#</td>\n",
       "      <td>61</td>\n",
       "      <td>166</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>375</td>\n",
       "      <td>195</td>\n",
       "      <td>6525589890</td>\n",
       "      <td>北京</td>\n",
       "      <td>2019-08-09 17:30:23</td>\n",
       "      <td>https://weibo.cn/comment/I1revf6wd</td>\n",
       "      <td>['中']</td>\n",
       "      <td>[no comment accessible]</td>\n",
       "      <td>:昨天上午，中国核潜发射全球打击的巨浪3型导弹，连发4颗。巨浪3是核导弹，射程13000公里...</td>\n",
       "      <td>507</td>\n",
       "      <td>2909</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    view_num  inform_num  reported_id reported_address            post_time  \\\n",
       "0         63           1   5144465848               北京  2019-08-09 22:54:39   \n",
       "1        211           1   6557230118               其他  2019-08-10 12:41:03   \n",
       "2         21           1   2704669457               山东  2019-08-09 17:34:13   \n",
       "3         14           2   5679726425               其他  2019-08-09 17:42:41   \n",
       "4         11           1   7267952918               北京  2019-08-09 20:50:41   \n",
       "5         12           1   1885799302               浙江  2019-08-10 11:29:35   \n",
       "6         11           1   6321164854               其他  2019-08-09 18:34:35   \n",
       "7         14           1   5974658278               浙江  2019-08-09 17:06:24   \n",
       "8         11           4   1915596045               上海  2019-08-09 21:23:02   \n",
       "9         12           1   1799653220               山东  2019-08-09 13:41:55   \n",
       "10        23           7   2966521665               广东  2019-08-10 13:01:35   \n",
       "11        13           1   5040718691               广东  2019-08-10 09:39:05   \n",
       "12        13           1   3676552201               其他  2019-08-09 12:57:04   \n",
       "13        25           1   2614436545               浙江  2019-08-09 16:40:03   \n",
       "14        73           1   3807973089               广西  2019-08-09 21:47:58   \n",
       "15        25           1   2866073222               江苏  2019-08-10 22:02:25   \n",
       "16        28           1   2924424367               上海                 None   \n",
       "17        17           1   3347738904               山东                 None   \n",
       "18        73           1   5311097831               河北  2019-08-10 18:58:46   \n",
       "19       375         195   6525589890               北京  2019-08-09 17:30:23   \n",
       "\n",
       "                          link_to_post reported_credit  \\\n",
       "0   https://weibo.cn/comment/I1tm7zm98           ['中']   \n",
       "1   https://weibo.cn/comment/I1yLyzrSI           ['中']   \n",
       "2   https://weibo.cn/comment/I1rg3Acxm           ['中']   \n",
       "3   https://weibo.cn/comment/I1rjuCZCd           ['中']   \n",
       "4   https://weibo.cn/comment/I1sxOmaRI           ['中']   \n",
       "5   https://weibo.cn/comment/I1yiyf91T           ['中']   \n",
       "6   https://weibo.cn/comment/I1rEz341I           ['中']   \n",
       "7   https://weibo.cn/comment/I1r4LAqjo           ['中']   \n",
       "8   https://weibo.cn/comment/I1sKW9ult           ['中']   \n",
       "9   https://weibo.cn/comment/I1pJLzBkT           ['中']   \n",
       "10  https://weibo.cn/comment/I1yTU02qd           ['中']   \n",
       "11  https://weibo.cn/comment/I1xzHCAI0           ['中']   \n",
       "12  https://weibo.cn/comment/I1przmR59           ['中']   \n",
       "13  https://weibo.cn/comment/I1qU4ur1S          ['正常']   \n",
       "14  https://weibo.cn/comment/I1sV3rl76           ['中']   \n",
       "15  https://weibo.cn/comment/I1Crq76cs           ['中']   \n",
       "16                                  nn           ['中']   \n",
       "17                                  nn           ['中']   \n",
       "18  https://weibo.cn/comment/I1BeShFSq           ['中']   \n",
       "19  https://weibo.cn/comment/I1revf6wd           ['中']   \n",
       "\n",
       "                   comments  \\\n",
       "0   [no comment accessible]   \n",
       "1   [no comment accessible]   \n",
       "2   [no comment accessible]   \n",
       "3   [no comment accessible]   \n",
       "4   [no comment accessible]   \n",
       "5   [no comment accessible]   \n",
       "6   [no comment accessible]   \n",
       "7   [no comment accessible]   \n",
       "8   [no comment accessible]   \n",
       "9   [no comment accessible]   \n",
       "10  [no comment accessible]   \n",
       "11  [no comment accessible]   \n",
       "12  [no comment accessible]   \n",
       "13  [no comment accessible]   \n",
       "14  [no comment accessible]   \n",
       "15  [no comment accessible]   \n",
       "16                [deleted]   \n",
       "17                [deleted]   \n",
       "18  [no comment accessible]   \n",
       "19  [no comment accessible]   \n",
       "\n",
       "                                        weibo_content repost_num thumbs_up  \\\n",
       "0                   :【8岁女孩因无钱治病, 向父母连说三声“谢谢”, 自拔氧气管离世         42       508   \n",
       "1                   :【8岁女孩因无钱治病, 向父母连说三声“谢谢”, 自拔氧气管离世         12       156   \n",
       "2   :中国天气网讯 中央气象台8月9日6时发布台风🌀红色预警。预计，“利奇马”将以每小时20公里...          6        14   \n",
       "3              :这次台风🌀（利奇马）登陆乐清湾 http://t.cn/AiTCHF22           3        21   \n",
       "4                      :分享视频 台州 http://t.cn/AiTpSJSD           0         0   \n",
       "5   :#风王利奇马登陆浙江温岭#  台风登陆现场：所经之处四处“飞沙走石”，连汽车也站不稳啊！ ...          0         4   \n",
       "6                  :台风天 台州·金都花园 http://t.cn/AiTNGcT3           0         0   \n",
       "7     :台州最新资讯真的要哈厮人啊#台风##台州# 临沂 http://t.cn/AiTCfXZW           0         5   \n",
       "8    :#超强台风利奇马来了# 没事别出门，出门注意安全！ http://t.cn/AiTpTnH2          12        68   \n",
       "9                    :#浙江台风# 台州 http://t.cn/AiTKfZXm           0         4   \n",
       "10  :#宁波一村庄爆发山洪#看看椒江一桥二桥多严重，在浙江的朋友们小心#台风利奇马# http:...          9        52   \n",
       "11  :#浙江台风##台风利奇马#继续跟进报道，工地吊机吹倒砸向附近居民楼，胆小者勿入，以免引起极...          0         2   \n",
       "12                     :特大台风席卷台州 台州 狂歌走天涯331004的微博视频           2         4   \n",
       "13                                          :台风你真的很可怕          7        18   \n",
       "14                   :#台风天骑手停送外卖##台风# 请给暴风雨中的这个外卖小哥点赞        117      4561   \n",
       "15  :#台风利奇马已致417万人受灾#鸟瞰台风“利奇马”，横扫人类，如世界末日席卷而来。太恐怖！...         23        75   \n",
       "16                                            deleted    deleted   deleted   \n",
       "17                                            deleted    deleted   deleted   \n",
       "18                                     :#台风眼##临海全市被淹#         61       166   \n",
       "19  :昨天上午，中国核潜发射全球打击的巨浪3型导弹，连发4颗。巨浪3是核导弹，射程13000公里...        507      2909   \n",
       "\n",
       "   comment_num  \n",
       "0          111  \n",
       "1           50  \n",
       "2            8  \n",
       "3            3  \n",
       "4            0  \n",
       "5            0  \n",
       "6            4  \n",
       "7            1  \n",
       "8            8  \n",
       "9            1  \n",
       "10          13  \n",
       "11           2  \n",
       "12           3  \n",
       "13           4  \n",
       "14         352  \n",
       "15          19  \n",
       "16     deleted  \n",
       "17     deleted  \n",
       "18          28  \n",
       "19         318  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
